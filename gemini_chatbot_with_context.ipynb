{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlvaxTWY1wvM87ZRxTk2RD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjhalliday/python-examples/blob/main/gemini_chatbot_with_context.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chatbot uses what is called \"feedback loop\" aka \"recursive prompting\" so that gemini understands the chat context. The model's previous responses are used as input for subsequent queries, allowing the chatbot to maintain context and build on prior interactions. This technique can help create more coherent and contextually aware conversations by allowing the model to reference its own prior responses."
      ],
      "metadata": {
        "id": "xLq0CfLnaxKC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iZFzC9hbam0m"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can get an api key from google for free. Store it as an environment variable in google colab (clic on the key icon on the lefthand side toolbar)"
      ],
      "metadata": {
        "id": "_PP2sxjebaLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "NiBeXU4bbYOU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "LjP1pTNJ19TM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the simple chatbot:\n",
        "1. Get input from user\n",
        "2. Send input to Gemini to get a response (chat history is not provided as input to Gemini)\n",
        "3. Display response from Gemini\n",
        "4. Loop back to 1."
      ],
      "metadata": {
        "id": "0LyyrDUH53bE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message_context=\"\"\n",
        "while True:\n",
        "  user_input = input(\"You: \")\n",
        "  if user_input.lower() == 'exit':\n",
        "    break\n",
        "  prompt = f\"{message_context}\\nUser: {user_input}\\n\"\n",
        "  print(\"-------DEBUG MESSAGE CONTEXT------\")\n",
        "  print(f\"{prompt}\")\n",
        "  print(\"----------------------------------\")\n",
        "  response = model.generate_content(prompt)\n",
        "  print(\"Response:\", response.text)\n",
        "  message_context = f\"{prompt}{response.text}\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "7RHsHJ-n4wBd",
        "outputId": "0d7b8cbf-2aee-4e6d-cf05-03c11496b259"
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: Hi\n",
            "-------DEBUG MESSAGE CONTEXT------\n",
            "\n",
            "User: Hi\n",
            "\n",
            "----------------------------------\n",
            "Response: Assistant: Hello there, how can I assist you?\n",
            "You: My favourite colour is blue\n",
            "-------DEBUG MESSAGE CONTEXT------\n",
            "\n",
            "User: Hi\n",
            "Assistant: Hello there, how can I assist you?\n",
            "User: My favourite colour is blue\n",
            "\n",
            "----------------------------------\n",
            "Response: Assistant: That's great! Blue is a beautiful color.\n",
            "You: What is my favourite colour?\n",
            "-------DEBUG MESSAGE CONTEXT------\n",
            "\n",
            "User: Hi\n",
            "Assistant: Hello there, how can I assist you?\n",
            "User: My favourite colour is blue\n",
            "Assistant: That's great! Blue is a beautiful color.\n",
            "User: What is my favourite colour?\n",
            "\n",
            "----------------------------------\n",
            "Response: Assistant: You mentioned that your favourite colour is blue.\n",
            "You: exit\n"
          ]
        }
      ]
    }
  ]
}